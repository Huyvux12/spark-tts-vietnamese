# ğŸ¤ Spark-TTS Vietnamese - Text-to-Speech Tiáº¿ng Viá»‡t

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Model-yellow)](https://huggingface.co/huyvux3005/spark-tts-vietnamese-5hourr_16bit)

Dá»± Ã¡n fine-tune mÃ´ hÃ¬nh **Spark-TTS** cho tiáº¿ng Viá»‡t vá»›i 2 giá»ng nÃ³i khÃ¡c nhau, sá»­ dá»¥ng thÆ° viá»‡n **Unsloth** Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™ training x2. Dá»± Ã¡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y trÃªn **Google Colab/Kaggle** vá»›i GPU T4 miá»…n phÃ­.

## ğŸ“‹ Má»¥c Lá»¥c

- [Giá»›i Thiá»‡u](#-giá»›i-thiá»‡u)
- [YÃªu Cáº§u Há»‡ Thá»‘ng](#-yÃªu-cáº§u-há»‡-thá»‘ng)
- [Cáº¥u TrÃºc Project](#-cáº¥u-trÃºc-project)
- [Demo Ã‚m Thanh](#-demo-Ã¢m-thanh)
- [HÆ°á»›ng Dáº«n Finetune](#-hÆ°á»›ng-dáº«n-finetune)
  - [TrÃªn Colab/Kaggle](#trÃªn-colabkaggle)
  - [TrÃªn Local](#trÃªn-local)
- [HÆ°á»›ng Dáº«n Inference](#-hÆ°á»›ng-dáº«n-inference)
- [TÃ i Liá»‡u Tham Kháº£o](#-tÃ i-liá»‡u-tham-kháº£o)

---

## ğŸ¯ Giá»›i Thiá»‡u

### CÃ´ng nghá»‡ sá»­ dá»¥ng

| CÃ´ng nghá»‡ | MÃ´ táº£ |
|-----------|-------|
| **Spark-TTS** | MÃ´ hÃ¬nh TTS dá»±a trÃªn LLM, sá»­ dá»¥ng BiCodec Ä‘á»ƒ mÃ£ hÃ³a audio thÃ nh token |
| **Unsloth** | ThÆ° viá»‡n tá»‘i Æ°u training, tÄƒng tá»‘c x2 vÃ  giáº£m VRAM |
| **LoRA** | Ká»¹ thuáº­t fine-tune hiá»‡u quáº£, chá»‰ train 12% tham sá»‘ |
| **BiCodec** | Tokenizer chuyá»ƒn Ä‘á»•i audio â†” semantic/global tokens |

### 2 Giá»ng nÃ³i Ä‘Æ°á»£c train

| Giá»ng | Nguá»“n | Äáº·c Ä‘iá»ƒm |
|-------|-------|----------|
| `@W2WMovie` | KÃªnh YouTube W2WMovie | Giá»ng review phim, rÃµ rÃ ng, chuyÃªn nghiá»‡p |
| `@ThanhPahm` | KÃªnh YouTube ThanhPahm | Giá»ng tá»± nhiÃªn, phong cÃ¡ch riÃªng |

---

## ğŸ’» YÃªu Cáº§u Há»‡ Thá»‘ng

### Cháº¡y trÃªn Colab/Kaggle (Khuyáº¿n nghá»‹)

| ThÃ nh pháº§n | YÃªu cáº§u |
|------------|---------|
| GPU | NVIDIA T4 (miá»…n phÃ­) |
| VRAM | ~15GB |
| Runtime | Python 3.10+ |

### Cháº¡y trÃªn Local

| ThÃ nh pháº§n | YÃªu cáº§u |
|------------|---------|
| GPU | NVIDIA vá»›i VRAM â‰¥ 15GB (RTX 3090, 4090, A100...) |
| CUDA | 12.x |
| Python | 3.10+ |
| RAM | â‰¥ 16GB |

---

## ğŸ“ Cáº¥u TrÃºc Project

```
projecet3/
â”œâ”€â”€ finetune_training.ipynb      # Notebook fine-tune model
â”œâ”€â”€ spark_tts_inference.ipynb    # Notebook inference (cháº¡y model)
â”œâ”€â”€ thanhphamtesst.wav           # Demo giá»ng @ThanhPahm
â”œâ”€â”€ w2wmovie.wav                 # Demo giá»ng @W2WMovie
â”œâ”€â”€ paper_sparktts.pdf           # Paper gá»‘c Spark-TTS
â”œâ”€â”€ 2006.13979v2.pdf             # Paper tham kháº£o
â””â”€â”€ README.md                    # File nÃ y
```

---

## ğŸ”Š Demo Ã‚m Thanh

Nghe thá»­ 2 giá»ng nÃ³i Ä‘Ã£ Ä‘Æ°á»£c train:

### Giá»ng @ThanhPahm
<audio controls>
  <source src="thanhphamtesst.wav" type="audio/wav">
  TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ audio. <a href="thanhphamtesst.wav">Táº£i file táº¡i Ä‘Ã¢y</a>
</audio>

ğŸ“¥ [Táº£i file thanhphamtesst.wav](thanhphamtesst.wav)

### Giá»ng @W2WMovie  
<audio controls>
  <source src="w2wmovie.wav" type="audio/wav">
  TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ audio. <a href="w2wmovie.wav">Táº£i file táº¡i Ä‘Ã¢y</a>
</audio>

ğŸ“¥ [Táº£i file w2wmovie.wav](w2wmovie.wav)

> **LÆ°u Ã½:** GitHub khÃ´ng há»— trá»£ phÃ¡t audio trá»±c tiáº¿p trong README. Clone repo vá» local hoáº·c sá»­ dá»¥ng GitHub Pages Ä‘á»ƒ nghe.

---

## ğŸš€ HÆ°á»›ng Dáº«n Finetune

### TrÃªn Colab/Kaggle

#### BÆ°á»›c 1: CÃ i Ä‘áº·t dependencies

```python
%%capture
!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu128
!pip install unsloth
!pip install transformers==4.55.4
!pip install --no-deps trl==0.22.2
!git clone https://github.com/SparkAudio/Spark-TTS
!pip install omegaconf einx huggingface_hub
```

#### BÆ°á»›c 2: Load model vá»›i Unsloth

```python
from unsloth import FastModel
from huggingface_hub import snapshot_download
import torch

# Download Spark-TTS base model
snapshot_download("unsloth/Spark-TTS-0.5B", local_dir="Spark-TTS-0.5B")

# Load model vá»›i Unsloth (tÄƒng tá»‘c x2)
model, tokenizer = FastModel.from_pretrained(
    model_name="Spark-TTS-0.5B/LLM",
    max_seq_length=2048,
    dtype=torch.float32,  # Spark-TTS chá»‰ hoáº¡t Ä‘á»™ng vá»›i float32
    full_finetuning=False,
    load_in_4bit=False,
)
```

#### BÆ°á»›c 3: Cáº¥u hÃ¬nh LoRA (12% tham sá»‘)

```python
model = FastModel.get_peft_model(
    model,
    r=128,  # KÃ­ch thÆ°á»›c ma tráº­n LoRA
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                    "gate_proj", "up_proj", "down_proj"],
    lora_alpha=128,
    lora_dropout=0,  # Äáº·t 0 Ä‘á»ƒ tá»‘i Æ°u VRAM
    bias="none",
    use_gradient_checkpointing="unsloth",
    random_state=3407,
)
```

#### BÆ°á»›c 4: Chuáº©n bá»‹ Dataset

**CÃ¡ch 1: Tá»« HuggingFace Datasets**
```python
from datasets import load_dataset
dataset = load_dataset("your_username/your_dataset", split="train")
```

**CÃ¡ch 2: Tá»« Kaggle (dáº¡ng Arrow)**
```python
from datasets import load_from_disk, concatenate_datasets

dataset1 = load_from_disk("/kaggle/input/thanhpahm-tts-standardized")
dataset2 = load_from_disk("/kaggle/input/w2wmovie-voice-2-standardized")
dataset = concatenate_datasets([dataset1, dataset2]).shuffle(seed=42)
```

#### BÆ°á»›c 5: Training vá»›i SFTTrainer

```python
from trl import SFTConfig, SFTTrainer

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    dataset_text_field="text",
    max_seq_length=2048,
    args=SFTConfig(
        per_device_train_batch_size=2,
        gradient_accumulation_steps=4,
        num_train_epochs=5,
        learning_rate=2e-4,
        optim="adamw_8bit",
        output_dir="outputs",
        report_to="wandb",  # Optional: log lÃªn Weights & Biases
    ),
)

trainer.train()
```

#### BÆ°á»›c 6: Push model lÃªn HuggingFace

```python
model.push_to_hub("your_username/spark-tts-vietnamese", token="hf_xxxxx")
tokenizer.push_to_hub("your_username/spark-tts-vietnamese", token="hf_xxxxx")
```

---

### TrÃªn Local

#### BÆ°á»›c 1: Clone repository

```bash
git clone https://github.com/your_username/spark-tts-vietnamese.git
cd spark-tts-vietnamese
```

#### BÆ°á»›c 2: Táº¡o mÃ´i trÆ°á»ng áº£o

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

#### BÆ°á»›c 3: CÃ i Ä‘áº·t dependencies

```bash
# CÃ i PyTorch vá»›i CUDA 12.x
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# CÃ i cÃ¡c thÆ° viá»‡n cÃ²n láº¡i
pip install unsloth transformers==4.55.4 trl==0.22.2 omegaconf einx huggingface_hub wandb jupyter

# Clone Spark-TTS
git clone https://github.com/SparkAudio/Spark-TTS
```

#### BÆ°á»›c 4: Cháº¡y Jupyter Notebook

```bash
jupyter notebook finetune_training.ipynb
```

#### âš ï¸ LÆ°u Ã½ khi train local

- **VRAM tá»‘i thiá»ƒu**: 15GB (RTX 3090, 4090, A100...)
- **Kiá»ƒu dá»¯ liá»‡u**: Pháº£i dÃ¹ng `torch.float32`, khÃ´ng há»— trá»£ fp16/bf16
- **Gradient checkpointing**: Báº­t `"unsloth"` Ä‘á»ƒ tiáº¿t kiá»‡m VRAM
- **Batch size**: Giáº£m xuá»‘ng 1 náº¿u bá»‹ OOM (Out of Memory)

---

## ğŸ™ï¸ HÆ°á»›ng Dáº«n Inference

### CÃ i Ä‘áº·t nhanh

```python
!pip install einx transformers soundfile huggingface_hub
!git clone https://github.com/SparkAudio/Spark-TTS
```

### Load model tá»« HuggingFace

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from huggingface_hub import snapshot_download
import sys

sys.path.append('Spark-TTS')
from sparktts.models.audio_tokenizer import BiCodecTokenizer

# Load LLM Ä‘Ã£ fine-tune
model = AutoModelForCausalLM.from_pretrained("huyvux3005/spark-tts-vietnamese-5hourr_16bit")
tokenizer = AutoTokenizer.from_pretrained("huyvux3005/spark-tts-vietnamese-5hourr_16bit")

# Load BiCodec tokenizer
snapshot_download("unsloth/Spark-TTS-0.5B", local_dir="Spark-TTS-0.5B")
audio_tokenizer = BiCodecTokenizer("Spark-TTS-0.5B", "cuda")
```

### Cháº¡y inference vá»›i giá»ng nÃ³i tÃ¹y chá»n

```python
import torch
import re
import soundfile as sf

device = torch.device("cuda")
model.to(device)

# Chá»n giá»ng: @W2WMovie hoáº·c @ThanhPahm
chosen_voice = "@W2WMovie"
text = "Bá»™ phim nÃ y thá»±c sá»± lÃ  má»™t kiá»‡t tÃ¡c!"

# Táº¡o prompt
input_text = f"{chosen_voice}: {text}"
prompt = f"<|task_tts|><|start_content|>{input_text}<|end_content|><|start_global_token|>"

# Generate tokens
inputs = tokenizer([prompt], return_tensors="pt").to(device)
generated_ids = model.generate(**inputs, max_new_tokens=2048)

# Parse tokens
output_text = tokenizer.decode(generated_ids[0], skip_special_tokens=False)
semantic_tokens = re.findall(r"<\|bicodec_semantic_(\d+)\|>", output_text)
global_tokens = re.findall(r"<\|bicodec_global_(\d+)\|>", output_text)

# Detokenize thÃ nh audio
audio_tokenizer.model.to(device)
wav = audio_tokenizer.detokenize(
    torch.tensor([int(t) for t in global_tokens]).unsqueeze(0).to(device),
    torch.tensor([int(t) for t in semantic_tokens]).unsqueeze(0).to(device)
)

# LÆ°u file
sf.write("output.wav", wav, 16000)
```

### Nghe káº¿t quáº£ trong Notebook

```python
from IPython.display import Audio, display
display(Audio("output.wav"))
```

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

- ğŸ“„ [Spark-TTS Paper (arXiv:2503.01710)](https://arxiv.org/abs/2503.01710) â€” Paper gá»‘c vá» kiáº¿n trÃºc Spark-TTS
- ğŸ“˜ [Unsloth TTS Fine-tuning Guide](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning) â€” HÆ°á»›ng dáº«n fine-tune TTS vá»›i Unsloth
- ğŸ”§ [Spark-TTS GitHub](https://github.com/SparkAudio/Spark-TTS) â€” Repository chÃ­nh thá»©c
- ğŸ¤— [Model trÃªn HuggingFace](https://huggingface.co/huyvux3005/spark-tts-vietnamese-5hourr_16bit) â€” Model Ä‘Ã£ fine-tune

---


